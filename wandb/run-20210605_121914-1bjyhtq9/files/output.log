Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [4, 8, 16, 32],
 'CROP_RESIZE_WITH_MAX_POOL': False,
 'CUDA': False,
 'DATA_DIR': '/own_files/lanyi/objDet/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'vgg16',
 'FEAT_STRIDE': [16],
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MAX_NUM_GT_BOXES': 50,
 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,
               'FIXED_LAYERS': 5,
               'REGU_DEPTH': False,
               'WEIGHT_DECAY': 4e-05},
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'align',
 'POOLING_SIZE': 7,
 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},
 'RNG_SEED': 3,
 'ROOT_DIR': '/own_files/lanyi/objDet',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 256,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'BN_TRAIN': False,
           'DISPLAY': 10,
           'DOUBLE_BIAS': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.01,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'res101_faster_rcnn',
           'STEPSIZE': [30000],
           'SUMMARY_INTERVAL': 180,
           'TRIM_HEIGHT': 600,
           'TRIM_WIDTH': 600,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0005},
 'USE_GPU_NMS': True}
loading annotations into memory...
Done (t=11.82s)
creating index...
index created!
loading annotations into memory...
Done (t=0.69s)
creating index...
index created!
Loaded dataset `coco_2014_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
coco_2014_train gt roidb loaded from /own_files/lanyi/objDet/data/cache/coco_2014_train_gt_roidb.pkl
done
Preparing training data...
done
loading annotations into memory...
Done (t=17.45s)
creating index...
index created!
loading annotations into memory...
Done (t=0.73s)
creating index...
index created!
before filtering, there are 165566 images...
after filtering, there are 164162 images...
164162 roidb entries
Loaded dataset `clipart1k_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
clipart1k_train gt roidb loaded from /own_files/lanyi/objDet/data/cache/clipart1k_train_gt_roidb.pkl
done
Preparing training data...
done
before filtering, there are 1000 images...
after filtering, there are 1000 images...
Loading pretrained weights from data/pretrained_model/vgg16_caffe.pth
loading checkpoint results/vgg16/caption_model_decay10_dw1/cap_faster_rcnn_1_6_102600.pth
loaded checkpoint results/vgg16/caption_model_decay10_dw1/cap_faster_rcnn_1_6_102600.pth
use glove embedding
loading checkpoint results/vgg16/caption_model_decay10_dw1/cap_lstm_1_6_102600.pth
loaded checkpoint results/vgg16/caption_model_decay10_dw1/cap_lstm_1_6_102600.pth
[session 1][epoch  0][iter    0/13680] loss: 6.5378, dann_loss: 1.3116, lr: 4.00e-04
			fg/bg=(355/2717), time cost: 16.605058
			rpn_cls: 0.7363, rpn_box: 0.5101, rcnn_cls: 5.0548, rcnn_box 0.2365
[session 1][epoch  0][iter  100/13680] loss: 1.8963, dann_loss: 1.4001, lr: 4.00e-04
			fg/bg=(459/2613), time cost: 277.008993
			rpn_cls: 0.3370, rpn_box: 0.2053, rcnn_cls: 0.7087, rcnn_box 0.3103
[session 1][epoch  0][iter  200/13680] loss: 1.5254, dann_loss: 1.4001, lr: 4.00e-04
			fg/bg=(447/2625), time cost: 276.660904
			rpn_cls: 0.2556, rpn_box: 0.0780, rcnn_cls: 0.8637, rcnn_box 0.3561
[session 1][epoch  0][iter  300/13680] loss: 1.4821, dann_loss: 1.3894, lr: 4.00e-04
			fg/bg=(445/2627), time cost: 274.687282
			rpn_cls: 0.2150, rpn_box: 0.1494, rcnn_cls: 0.7658, rcnn_box 0.3528
[session 1][epoch  0][iter  400/13680] loss: 1.4980, dann_loss: 1.4021, lr: 4.00e-04
			fg/bg=(607/2465), time cost: 276.861499
			rpn_cls: 0.3229, rpn_box: 0.1086, rcnn_cls: 1.0941, rcnn_box 0.4716
[session 1][epoch  0][iter  500/13680] loss: 1.4121, dann_loss: 1.3819, lr: 4.00e-04
			fg/bg=(413/2659), time cost: 277.897260
			rpn_cls: 0.2158, rpn_box: 0.1104, rcnn_cls: 0.6595, rcnn_box 0.2962
[session 1][epoch  0][iter  600/13680] loss: 1.4167, dann_loss: 1.3988, lr: 4.00e-04
			fg/bg=(296/2776), time cost: 276.317927
			rpn_cls: 0.2187, rpn_box: 0.0848, rcnn_cls: 0.4485, rcnn_box 0.2092
[session 1][epoch  0][iter  700/13680] loss: 1.4004, dann_loss: 1.3956, lr: 4.00e-04
			fg/bg=(397/2675), time cost: 279.443674
			rpn_cls: 0.1451, rpn_box: 0.0395, rcnn_cls: 0.5397, rcnn_box 0.2949
[session 1][epoch  0][iter  800/13680] loss: 1.3169, dann_loss: 1.3875, lr: 4.00e-04
			fg/bg=(525/2547), time cost: 276.011966
			rpn_cls: 0.2055, rpn_box: 0.1018, rcnn_cls: 0.6897, rcnn_box 0.4238
[session 1][epoch  0][iter  900/13680] loss: 1.3312, dann_loss: 1.3827, lr: 4.00e-04
			fg/bg=(610/2462), time cost: 279.421261
			rpn_cls: 0.2117, rpn_box: 0.1500, rcnn_cls: 0.6541, rcnn_box 0.3570
[session 1][epoch  0][iter 1000/13680] loss: 1.2803, dann_loss: 1.3728, lr: 4.00e-04
			fg/bg=(380/2692), time cost: 278.627881
			rpn_cls: 0.2331, rpn_box: 0.0905, rcnn_cls: 0.5598, rcnn_box 0.2715
[session 1][epoch  0][iter 1100/13680] loss: 1.2834, dann_loss: 1.3926, lr: 4.00e-04
			fg/bg=(672/2400), time cost: 278.309498
			rpn_cls: 0.2090, rpn_box: 0.0918, rcnn_cls: 0.8305, rcnn_box 0.5046
[session 1][epoch  0][iter 1200/13680] loss: 1.2385, dann_loss: 1.3798, lr: 4.00e-04
			fg/bg=(426/2646), time cost: 277.068061
			rpn_cls: 0.2210, rpn_box: 0.1036, rcnn_cls: 0.4652, rcnn_box 0.2989
[session 1][epoch  0][iter 1300/13680] loss: 1.2752, dann_loss: 1.3886, lr: 4.00e-04
			fg/bg=(551/2521), time cost: 277.401215
			rpn_cls: 0.2384, rpn_box: 0.1653, rcnn_cls: 0.6445, rcnn_box 0.3669
[session 1][epoch  0][iter 1400/13680] loss: 1.2566, dann_loss: 1.3822, lr: 4.00e-04
			fg/bg=(529/2543), time cost: 276.808742
			rpn_cls: 0.1961, rpn_box: 0.0741, rcnn_cls: 0.5964, rcnn_box 0.3755
[session 1][epoch  0][iter 1500/13680] loss: 1.2402, dann_loss: 1.3848, lr: 4.00e-04
			fg/bg=(599/2473), time cost: 281.521773
			rpn_cls: 0.2014, rpn_box: 0.1269, rcnn_cls: 0.6006, rcnn_box 0.4138
[session 1][epoch  0][iter 1600/13680] loss: 1.2115, dann_loss: 1.3847, lr: 4.00e-04
			fg/bg=(447/2625), time cost: 275.803493
			rpn_cls: 0.1595, rpn_box: 0.0393, rcnn_cls: 0.5374, rcnn_box 0.3024
Traceback (most recent call last):
  File "trainval_cap_net.py", line 680, in <module>
    _, _, pred, cap_h_pred, cap_c_pred = lstm.greedy_search(
  File "/own_files/lanyi/objDet/lib/model/caption_modules/model.py", line 346, in greedy_search
    attention_weighted_encoding, alpha = self.attention(features, h)
  File "/afs/cs.pitt.edu/usr0/law190/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/own_files/lanyi/objDet/lib/model/caption_modules/model.py", line 42, in forward
    att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(
  File "/afs/cs.pitt.edu/usr0/law190/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/afs/cs.pitt.edu/usr0/law190/anaconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 94, in forward
    return F.relu(input, inplace=self.inplace)
  File "/afs/cs.pitt.edu/usr0/law190/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 914, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 15.75 GiB total capacity; 14.61 GiB already allocated; 7.00 MiB free; 15.01 GiB reserved in total by PyTorch)
